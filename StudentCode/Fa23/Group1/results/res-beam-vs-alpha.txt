Starting experiment
Running with options: {'ai': 'both', 'depth': 25, 'depth2': 2, 'maxStates': 500000, 'agent': 'BeamAgent', 'agent2': 'AlphaBetaAgent', 'eval': 'eval_territory', 'eval2': None, 'width': 10, 'width2': None}
BeamAgent picked (K(1), 0, 0) with value -996.0, states explored: 375 
AI action: K(1) to (0, 0)
 |------|------|------|------|------|------|
0| K(1) |      |      |      |      |      |
 |------|------|------|------|------|------|
1|      |      |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      |      |      |      |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      |      |      |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

AlphaBetaAgent picked (K(2), 2, 2) with value 0.5, states explored: 11309 
AI action: K(2) to (2, 2)
 |------|------|------|------|------|------|
0| K(1) |      |      |      |      |      |
 |------|------|------|------|------|------|
1|      |      |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      | K(2) |      |      |      |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      |      |      |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

BeamAgent picked (K(1), 0, 2) with value 997.5, states explored: 225 
AI action: K(1) to (0, 2)
 |------|------|------|------|------|------|
0| K(1) |      | K(1) |      |      |      |
 |------|------|------|------|------|------|
1|      |      |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      | K(2) |      |      |      |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      |      |      |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

AlphaBetaAgent picked (K(2), 1, 1) with value -1.2999999999999998, states explored: 4877 
AI action: K(2) to (1, 1)
 |------|------|------|------|------|------|
0|      |      |      |      |      |      |
 |------|------|------|------|------|------|
1|      | K(2) |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      |      |      |      |
 |------|------|------|------|------|------|
3|      |      |      | K(2) |      |      |
 |------|------|------|------|------|------|
4|      |      |      |      |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

BeamAgent picked (K(1), 0, 1) with value 997.3, states explored: 225 
AI action: K(1) to (0, 1)
 |------|------|------|------|------|------|
0|      | K(1) |      |      |      |      |
 |------|------|------|------|------|------|
1|      |      |      |      |      |      |
 |------|------|------|------|------|------|
2|      | K(2) |      |      |      |      |
 |------|------|------|------|------|------|
3|      |      |      | K(2) |      |      |
 |------|------|------|------|------|------|
4|      |      |      |      |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

AlphaBetaAgent picked (K(2), 1, 0) with value -3.1, states explored: 8343 
AI action: K(2) to (1, 0)
 |------|------|------|------|------|------|
0|      |      |      |      |      |      |
 |------|------|------|------|------|------|
1| K(2) |      |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      |      |      |      |
 |------|------|------|------|------|------|
3|      |      | K(2) | K(2) |      |      |
 |------|------|------|------|------|------|
4|      |      |      |      |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

BeamAgent picked (K(1), 2, 1) with value -996.4, states explored: 179 
AI action: K(1) to (2, 1)
 |------|------|------|------|------|------|
0|      |      |      |      |      |      |
 |------|------|------|------|------|------|
1|      |      |      |      |      |      |
 |------|------|------|------|------|------|
2|      | K(1) |      |      |      |      |
 |------|------|------|------|------|------|
3|      |      |      | K(2) |      |      |
 |------|------|------|------|------|------|
4|      |      |      | K(2) |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

AlphaBetaAgent picked (K(2), 2, 3) with value -99.60000000000001, states explored: 11108 
AI action: K(2) to (2, 3)
 |------|------|------|------|------|------|
0|      |      |      |      |      |      |
 |------|------|------|------|------|------|
1|      |      |      |      |      |      |
 |------|------|------|------|------|------|
2|      | K(1) |      |      |      |      |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      |      |      |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

BeamAgent picked (K(1), 2, 0) with value -996.4, states explored: 159 
AI action: K(1) to (2, 0)
 |------|------|------|------|------|------|
0|      |      |      |      |      |      |
 |------|------|------|------|------|------|
1|      |      |      |      |      |      |
 |------|------|------|------|------|------|
2| K(1) |      | K(1) |      |      |      |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      |      |      |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

AlphaBetaAgent picked (C(2), 1, 1) with value -124.4, states explored: 22280 
AI action: C(2) to (1, 1)
 |------|------|------|------|------|------|
0|      |      |      |      |      |      |
 |------|------|------|------|------|------|
1|      | C(2) |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      |      |      |      |
 |------|------|------|------|------|------|
3|      |      |      | K(1) |      |      |
 |------|------|------|------|------|------|
4|      |      |      |      |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

BeamAgent picked (K(1), 1, 3) with value -239.20000000000002, states explored: 189 
AI action: K(1) to (1, 3)
 |------|------|------|------|------|------|
0|      |      |      |      |      |      |
 |------|------|------|------|------|------|
1|      | C(2) |      | K(1) |      |      |
 |------|------|------|------|------|------|
2|      |      |      |      |      |      |
 |------|------|------|------|------|------|
3|      |      |      | K(1) |      |      |
 |------|------|------|------|------|------|
4|      |      |      |      |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

AlphaBetaAgent picked (C(2), 2, 3) with value -148.4, states explored: 25617 
AI action: C(2) to (2, 3)
 |------|------|------|------|------|------|
0|      |      |      | K(1) |      |      |
 |------|------|------|------|------|------|
1|      | C(2) |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      | C(2) |      |      |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      |      | K(1) |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

BeamAgent picked (K(1), 2, 5) with value -996.2, states explored: 203 
AI action: K(1) to (2, 5)
 |------|------|------|------|------|------|
0|      |      |      | K(1) |      |      |
 |------|------|------|------|------|------|
1|      | C(2) |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      | C(2) |      | K(1) |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      |      | K(1) |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

AlphaBetaAgent picked (K(2), 0, 1) with value -147.4, states explored: 12163 
AI action: K(2) to (0, 1)
 |------|------|------|------|------|------|
0|      | K(2) |      | K(1) |      |      |
 |------|------|------|------|------|------|
1|      | C(2) |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      | C(2) |      | K(1) |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      |      | K(1) |      |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

BeamAgent picked (K(1), 4, 5) with value -995.6, states explored: 287 
AI action: K(1) to (4, 5)
 |------|------|------|------|------|------|
0|      | K(2) |      | K(1) |      |      |
 |------|------|------|------|------|------|
1|      | C(2) |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      | C(2) |      | K(1) |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      |      | K(1) |      | K(1) |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

AlphaBetaAgent picked (C(2), 4, 4) with value -149.6, states explored: 17371 
AI action: C(2) to (4, 4)
 |------|------|------|------|------|------|
0|      | K(2) |      | K(1) |      |      |
 |------|------|------|------|------|------|
1|      | C(2) |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      | C(2) |      | K(1) |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      | K(1) |      | C(2) |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

BeamAgent picked (K(1), 0, 5) with value -995.0, states explored: 303 
AI action: K(1) to (0, 5)
 |------|------|------|------|------|------|
0|      | K(2) |      | K(1) |      | K(1) |
 |------|------|------|------|------|------|
1|      | C(2) |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      | C(2) |      | K(1) |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      | K(1) |      | C(2) |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

AlphaBetaAgent picked (K(2), 2, 1) with value -193.4, states explored: 2750 
AI action: K(2) to (2, 1)
 |------|------|------|------|------|------|
0|      |      |      | K(1) |      | K(1) |
 |------|------|------|------|------|------|
1|      |      |      |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      | C(2) |      | K(1) |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      | K(1) |      | C(2) |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

BeamAgent picked (K(1), 2, 1) with value -995.2, states explored: 219 
AI action: K(1) to (2, 1)
 |------|------|------|------|------|------|
0|      |      |      | K(1) |      | K(1) |
 |------|------|------|------|------|------|
1|      |      |      |      |      |      |
 |------|------|------|------|------|------|
2|      | K(1) |      | C(2) |      | K(1) |
 |------|------|------|------|------|------|
3|      |      |      |      |      |      |
 |------|------|------|------|------|------|
4|      |      | K(1) |      | C(2) |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

AlphaBetaAgent picked (C(2), 1, 2) with value -997.8, states explored: 17347 
AI action: C(2) to (1, 2)
 |------|------|------|------|------|------|
0|      |      |      |      |      | K(1) |
 |------|------|------|------|------|------|
1|      |      | C(2) |      |      |      |
 |------|------|------|------|------|------|
2|      |      |      |      |      | K(1) |
 |------|------|------|------|------|------|
3| K(1) |      |      |      | C(2) |      |
 |------|------|------|------|------|------|
4|      |      | K(1) |      | C(2) |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

BeamAgent picked (K(1), 2, 0) with value -997.8, states explored: 11 
AI action: K(1) to (2, 0)
 |------|------|------|------|------|------|
0|      |      |      |      |      | K(1) |
 |------|------|------|------|------|------|
1|      |      | C(2) |      |      |      |
 |------|------|------|------|------|------|
2| K(1) |      |      |      |      | K(1) |
 |------|------|------|------|------|------|
3|      |      |      |      | C(2) |      |
 |------|------|------|------|------|------|
4| K(1) |      | K(1) |      | C(2) |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

AlphaBetaAgent picked (C(2), 2, 4) with value -997.8, states explored: 51218 
AI action: C(2) to (2, 4)
 |------|------|------|------|------|------|
0|      |      |      |      |      | K(1) |
 |------|------|------|------|------|------|
1|      |      | C(2) |      |      |      |
 |------|------|------|------|------|------|
2| K(1) |      |      |      | C(2) |      |
 |------|------|------|------|------|------|
3|      |      |      |      | C(2) |      |
 |------|------|------|------|------|------|
4| K(1) |      | K(1) |      | C(2) |      |
 |------|------|------|------|------|------|
5|      |      |      |      |      |      |
 |------|------|------|------|------|------|
    0      1      2      3      4      5    

Winner is: PlayerID.TWO in 22 plies
====> So far: p2 win percentage = 1.0
====> Final p2 win percentage: 1.0, avg plies: 22.0, time: 53.85195255279541 sec
